<!DOCTYPE html>
<html class="has-navbar-fixed-top">
<head>
    <meta charset="utf-8">
<title>Project Covid Admissions Based on Vaccine Progress, Part 3 -- Mixed-effect models and Bayesian Inference - The Practical Quant</title>
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.css">




<meta name="description" content="">





    <meta name="description" content="In the last two blogs, we went through linear regression and generalized linear regression in search of the best solution to the covid data by relaxing the assumptions of linear regression and OLS. Ba">
<meta property="og:type" content="article">
<meta property="og:title" content="Project Covid Admissions Based on Vaccine Progress, Part 3 -- Mixed-effect models and Bayesian Inference">
<meta property="og:url" content="http://yoursite.com/2021/10/02/projectcovidmixed/index.html">
<meta property="og:site_name" content="The Practical Quant">
<meta property="og:description" content="In the last two blogs, we went through linear regression and generalized linear regression in search of the best solution to the covid data by relaxing the assumptions of linear regression and OLS. Ba">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_27_0.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_43_0.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_46_1.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_50_0.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_53_0.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_54_0.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_61_1.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_68_1.png">
<meta property="og:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_cookie.png">
<meta property="article:published_time" content="2021-10-02T16:00:00.000Z">
<meta property="article:modified_time" content="2025-12-12T03:45:45.976Z">
<meta property="article:author" content="Yumeng Li">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_27_0.png">





<link rel="icon" href="/favicon.png">


<link rel="stylesheet" href="//fonts.googleapis.com/css?family=Ovo|Source+Code+Pro">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/bulma/0.6.2/css/bulma.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/css/lightgallery.min.css">
<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/css/justifiedGallery.min.css">


<link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/atom-one-light.min.css">


<link rel="stylesheet" href="/css/style.css">


<script defer src="//use.fontawesome.com/releases/v5.0.8/js/all.js"></script>


    
    
    
    
    
    
    
    
    
    

    


<meta name="generator" content="Hexo 5.0.0"></head>
<body>
    
<nav class="navbar is-transparent is-fixed-top navbar-main" role="navigation" aria-label="main navigation">
    <div class="container">
        <div class="navbar-brand">
            <a class="navbar-item navbar-logo" href="/">
                
                    
                    THE PRACTICAL QUANT
                    
                
            </a>
            <div class="navbar-burger">
                <span></span>
                <span></span>
                <span></span>
            </div>
        </div>
        
        <div class="navbar-menu navbar-start">
            
            <a class="navbar-item "
               href="/archives">Archives</a>
            
            <a class="navbar-item "
               href="/categories">Category</a>
            
            <a class="navbar-item "
               target="_blank" rel="noopener" href="http://allaboutmacros.com/">Blog</a>
            
            <a class="navbar-item "
               target="_blank" rel="noopener" href="https://www.linkedin.com/in/emmelineli/">Linkedin</a>
            
        </div>
        
        <div class="navbar-menu navbar-end">
            
            <a class="navbar-item search" title="Search" href="javascript:;">
                <i class="fas fa-search"></i>
            </a>
            
            
            
            <a class="navbar-item" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                
                <i class="fab fa-github"></i>
                
            </a>
               
            
        </div>
    </div>
</nav>

    <section class="section">
    <div class="container">
    <article class="article content gallery" itemscope itemprop="blogPost">
    <h1 class="article-title is-size-3 is-size-4-mobile" itemprop="name">
        
            Project Covid Admissions Based on Vaccine Progress, Part 3 -- Mixed-effect models and Bayesian Inference
        
    </h1>
    <div class="article-meta columns is-variable is-1 is-multiline is-mobile is-size-7-mobile">
        <span class="column is-narrow">
            <time datetime="2021-10-02T16:00:00.000Z" itemprop="datePublished">Oct 2 2021</time>
        </span>
        
        <span class="column is-narrow article-category">
            <i class="far fa-folder"></i>
            <a class="article-category-link" href="/categories/Applied-Statistics/">Applied Statistics</a>
        </span>
        
        
        <span class="column is-narrow">
            
            
            25 minutes read (About 3775 words)
        </span>
        
    </div>
    <div class="article-entry is-size-6-mobile" itemprop="articleBody">
    
        <html><head></head><body><p>In the last two blogs, we went through linear regression and generalized linear regression in search of the best solution to the covid data by relaxing the assumptions of linear regression and OLS. Based on what have done so far, our conclusion is negative binomial regression fit the data best. However, still, we have this problem that for some states with high vaccination rates, the increasing cases are over-estimated, and a few state such as FL and KY, are more like outliers to the model. Today, we are going to fixed these issues with the <strong>mixed-effects model</strong>, specifically, the generalized linear mixed-effects model(GLMM), which is very popular in biostatistics and econometrics, especially useful for economists when modeling cross-country macro data.</p>
<p>A <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Mixed_model">mixed-effects model</a> contains both fixed effects and random effects. They are particularly useful in settings where measurements are made on clusters of related statistical units. There are several ways people usually choose to deal with this type of inherently &#x201C;lumpy&#x201D; data.</p>
<h4 id="1-Pooled-Data-Regression"><a href="#1-Pooled-Data-Regression" class="headerlink" title="1. Pooled Data Regression"></a>1. Pooled Data Regression</h4><p>One can run a regular regression on $y$ versus $x$ ignoring the group information, like what we have done in the last two blogs.</p>
<p>It works but:</p>
<ul>
<li>It throws away useful information.</li>
<li>Linear Regression assumes observations are <strong>independent</strong> here they are not.</li>
<li>The $\alpha$ and $\beta$ coefficients are <em>unbiased estimates</em> (not bad).</li>
<li>The confidence intervals will be <strong>too optimistic</strong>.</li>
</ul>
<h4 id="2-Unpooled-Data-Regression"><a href="#2-Unpooled-Data-Regression" class="headerlink" title="2. Unpooled Data Regression"></a>2. Unpooled Data Regression</h4><p>Instead one can run a regression for each of the groups.</p>
<ul>
<li>One needs to estimate too many coefficients (51 $\alpha$s and 51 $\beta$s in our case).</li>
<li>This results in <strong>unbiased</strong>, but <strong>very noisy</strong> estimates if some groups have few observations.</li>
</ul>
<h4 id="3-Pooled-Slope-Unpooled-Intercept"><a href="#3-Pooled-Slope-Unpooled-Intercept" class="headerlink" title="3. Pooled Slope, Unpooled Intercept"></a>3. Pooled Slope, Unpooled Intercept</h4><p>We can instead fit a regression with a dummy variable for each group.</p>
<p>$$<br>    y_i = \alpha + \beta x + \rho^T Z_i<br>$$<br>where $\rho$ is now a vector with as many coefficients as groups, and $Z$ is a vector of dummies, one column per group (we must leave one group out to avoid co-linearity of Z).</p>
<p>This method:</p>
<ul>
<li>Pools information for the slope $\beta$.</li>
<li>Treats each group intercept independently. <strong>If some group $g$ has few examples $\rho_g$ will be noisy</strong>.</li>
</ul>
<h4 id="4-Penalized-Linear-Regression"><a href="#4-Penalized-Linear-Regression" class="headerlink" title="4. Penalized Linear Regression"></a>4. Penalized Linear Regression</h4><p>To pool over the different groups, we can introduce a <strong>regression penalty</strong> to penalize model coefficients to reduce the model degrees of freedom.</p>
<ul>
<li>Theoretically, the correct penalty is proportional to the ration of variances for the observations $\sigma_Y^2$ and the random effects $\sigma_\rho^2$.</li>
<li>Because there is no penalty for $\alpha$, the mean over all the population will be matched exactly.</li>
</ul>
<h4 id="5-Linear-Mixed-effect-Model"><a href="#5-Linear-Mixed-effect-Model" class="headerlink" title="5. Linear Mixed-effect Model"></a>5. Linear Mixed-effect Model</h4><p>For people who are familiar with penalized regressions and regularizations like lasso and rigid, the estimation of mixed models would be very straightforward as essentially, they are the same. Same result can be obtained with less work by fitting to a <strong>Linear Mixed Effect Model</strong> with <a target="_blank" rel="noopener" href="https://www.statsmodels.org/0.8.0/mixed_linear.html">statsmodels.mixed_linear</a> module. </p>
<h4 id="6-Generalized-Linear-Mixed-effects-Model-GLMM"><a href="#6-Generalized-Linear-Mixed-effects-Model-GLMM" class="headerlink" title="6. Generalized Linear Mixed-effects Model (GLMM)"></a>6. Generalized Linear Mixed-effects Model (GLMM)</h4><p>Today, as we already know that negative binomial distribution fits the covid data better, we will skip the linear mixed model and start with the non-linear GLMM. Since the model is relatively complex, we will be using a much cooler statistical inference method &#x2013; <strong>Bayesian</strong>.</p>
<h2 id="Preliminaries"><a href="#Preliminaries" class="headerlink" title="Preliminaries"></a>Preliminaries</h2><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np</span><br><span class="line"><span class="hljs-keyword">import</span> pandas <span class="hljs-keyword">as</span> pd</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt</span><br><span class="line"><span class="hljs-keyword">import</span> matplotlib.cm <span class="hljs-keyword">as</span> cm</span><br><span class="line"><span class="hljs-keyword">import</span> seaborn <span class="hljs-keyword">as</span> sns</span><br><span class="line"><span class="hljs-keyword">import</span> pymc3 <span class="hljs-keyword">as</span> pm</span><br><span class="line"><span class="hljs-keyword">import</span> arviz <span class="hljs-keyword">as</span> az</span><br><span class="line"><span class="hljs-keyword">import</span> sys</span><br><span class="line"><span class="hljs-keyword">import</span> covid_analysis <span class="hljs-keyword">as</span> covid</span><br></pre></td></tr></tbody></table></figure>

<p>As usual, let&#x2019;s prepare the data. Hospital admissions and vaccinations are from the CDC website, and the most up-to-date populations by state are from the US Census Bureau.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data_dir=<span class="hljs-string">&quot;../data&quot;</span></span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">hospitalizations=pd.read_csv(<span class="hljs-string">f&quot;<span class="hljs-subst">{data_dir}</span>/covid_hospitalizations.csv&quot;</span>,parse_dates=[<span class="hljs-string">&quot;date&quot;</span>])</span><br><span class="line">vaccinations=pd.read_csv(<span class="hljs-string">f&quot;<span class="hljs-subst">{data_dir}</span>/covid_vaccinations.csv&quot;</span>,parse_dates=[<span class="hljs-string">&quot;date&quot;</span>])</span><br><span class="line">population=pd.read_csv(<span class="hljs-string">f&quot;<span class="hljs-subst">{data_dir}</span>/population.csv&quot;</span>)</span><br><span class="line"></span><br><span class="line">event=<span class="hljs-string">&quot;admissions&quot;</span></span><br><span class="line">data=hospitalizations</span><br><span class="line"></span><br><span class="line">data=data.merge(vaccinations,on=[<span class="hljs-string">&quot;date&quot;</span>,<span class="hljs-string">&quot;state&quot;</span>])</span><br><span class="line">data=data.merge(population,on=<span class="hljs-string">&quot;state&quot;</span>)</span><br><span class="line">data[<span class="hljs-string">&quot;vaccinated&quot;</span>]=data[<span class="hljs-string">&quot;vaccinated&quot;</span>]/data[<span class="hljs-string">&quot;population&quot;</span>]</span><br><span class="line">data.head()</span><br></pre></td></tr></tbody></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>date</th>
      <th>state</th>
      <th>used_beds</th>
      <th>admissions</th>
      <th>vaccinated</th>
      <th>population</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>2021-06-10</td>
      <td>MT</td>
      <td>66.0</td>
      <td>16.0</td>
      <td>0.397597</td>
      <td>1080577</td>
    </tr>
    <tr>
      <th>1</th>
      <td>2021-06-21</td>
      <td>MT</td>
      <td>57.0</td>
      <td>13.0</td>
      <td>0.411614</td>
      <td>1080577</td>
    </tr>
    <tr>
      <th>2</th>
      <td>2021-08-05</td>
      <td>MT</td>
      <td>149.0</td>
      <td>23.0</td>
      <td>0.440153</td>
      <td>1080577</td>
    </tr>
    <tr>
      <th>3</th>
      <td>2021-07-15</td>
      <td>MT</td>
      <td>62.0</td>
      <td>9.0</td>
      <td>0.431722</td>
      <td>1080577</td>
    </tr>
    <tr>
      <th>4</th>
      <td>2021-08-21</td>
      <td>MT</td>
      <td>224.0</td>
      <td>59.0</td>
      <td>0.449196</td>
      <td>1080577</td>
    </tr>
  </tbody>
</table>
</div>



<p>Split the train and test data,</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># train dates</span></span><br><span class="line">start_train=<span class="hljs-string">&quot;2021-07-15&quot;</span></span><br><span class="line">end_train=<span class="hljs-string">&quot;2021-08-15&quot;</span></span><br><span class="line">train_data=data[(data[<span class="hljs-string">&apos;date&apos;</span>] &gt;= start_train) &amp; (data[<span class="hljs-string">&apos;date&apos;</span>] &lt;= end_train)].copy()</span><br><span class="line">date0=train_data[<span class="hljs-string">&quot;date&quot;</span>].min()</span><br><span class="line"><span class="hljs-comment"># test dates</span></span><br><span class="line">test_period=<span class="hljs-number">7</span> <span class="hljs-comment"># days</span></span><br><span class="line">test_end=pd.Timestamp(end_train)+pd.DateOffset(days=test_period)</span><br><span class="line">test_data=data[(data[<span class="hljs-string">&quot;date&quot;</span>]&gt;end_train) &amp; (data[<span class="hljs-string">&quot;date&quot;</span>]&lt;=test_end)].copy()</span><br></pre></td></tr></tbody></table></figure>

<p>Here we write a function to generate our desired matrix. This time, we will need an extra step to label data by state.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">define_variables</span>(<span class="hljs-params">data,date0</span>):</span></span><br><span class="line">        N=len(data)</span><br><span class="line">        T=(data[<span class="hljs-string">&quot;date&quot;</span>]-date0).dt.days/<span class="hljs-number">30</span></span><br><span class="line">        X=pd.DataFrame({<span class="hljs-string">&quot;const&quot;</span>:np.ones(N)})</span><br><span class="line">        X[<span class="hljs-string">&quot;vaccinated&quot;</span>]=data[<span class="hljs-string">&quot;vaccinated&quot;</span>].values</span><br><span class="line">        X[<span class="hljs-string">&quot;T&quot;</span>]=T.values</span><br><span class="line">        X[<span class="hljs-string">&quot;T2&quot;</span>]=T.values**<span class="hljs-number">2</span></span><br><span class="line">        P=data[<span class="hljs-string">&quot;population&quot;</span>].values </span><br><span class="line">        Z=pd.get_dummies(data[<span class="hljs-string">&quot;state&quot;</span>])        </span><br><span class="line">        <span class="hljs-keyword">return</span> X,Z,P</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">X_train,Z_train,P_train=define_variables(train_data,date0)</span><br><span class="line">Y_train=train_data[event]</span><br><span class="line">G_train=Z_train.values.argmax(axis=<span class="hljs-number">1</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>We have 51 regions in total,</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># number of states/regions</span></span><br><span class="line">K = G_train.max()+<span class="hljs-number">1</span></span><br><span class="line">K</span><br></pre></td></tr></tbody></table></figure>




<pre><code>51</code></pre>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># all states/regions</span></span><br><span class="line">states=Z_train.columns</span><br><span class="line">states</span><br></pre></td></tr></tbody></table></figure>




<pre><code>Index([&apos;AK&apos;, &apos;AL&apos;, &apos;AR&apos;, &apos;AZ&apos;, &apos;CA&apos;, &apos;CO&apos;, &apos;CT&apos;, &apos;DC&apos;, &apos;DE&apos;, &apos;FL&apos;, &apos;GA&apos;, &apos;HI&apos;,
       &apos;IA&apos;, &apos;ID&apos;, &apos;IL&apos;, &apos;IN&apos;, &apos;KS&apos;, &apos;KY&apos;, &apos;LA&apos;, &apos;MA&apos;, &apos;MD&apos;, &apos;ME&apos;, &apos;MI&apos;, &apos;MN&apos;,
       &apos;MO&apos;, &apos;MS&apos;, &apos;MT&apos;, &apos;NC&apos;, &apos;ND&apos;, &apos;NE&apos;, &apos;NH&apos;, &apos;NJ&apos;, &apos;NM&apos;, &apos;NV&apos;, &apos;NY&apos;, &apos;OH&apos;,
       &apos;OK&apos;, &apos;OR&apos;, &apos;PA&apos;, &apos;RI&apos;, &apos;SC&apos;, &apos;SD&apos;, &apos;TN&apos;, &apos;TX&apos;, &apos;UT&apos;, &apos;VA&apos;, &apos;VT&apos;, &apos;WA&apos;,
       &apos;WI&apos;, &apos;WV&apos;, &apos;WY&apos;],
      dtype=&apos;object&apos;)</code></pre>
<h2 id="Mixed-Negative-Binomial-Regression-Model"><a href="#Mixed-Negative-Binomial-Regression-Model" class="headerlink" title="Mixed Negative Binomial Regression Model"></a>Mixed Negative Binomial Regression Model</h2><h3 id="Model-Definition"><a href="#Model-Definition" class="headerlink" title="Model Definition"></a>Model Definition</h3><p>We have data from multiple dates, so it makes sense to incorporate Time as a extra variable.</p>
<p>\begin{eqnarray}<br>    \eta_{i,j}                  =&amp; \beta_0 + \beta_1 x_{i,j}  + \beta_2 t_{j} + \beta_3 t_{j}^2  + \rho_i\newline<br>    \rho_i \sim &amp; N(0,\sigma_{\rho}^2) \newline<br>    \lambda_{i,j} =&amp; e^{\eta_{i,j}} \newline<br>   y_{i,j}          \sim &amp; \text{NB}(y;\lambda_{i,j} P_i,\alpha)<br>\end{eqnarray}<br>with priors<br>\begin{eqnarray}<br>    \beta_0 \sim &amp; N( \bar{y},1) \newline<br>    \beta_i \sim &amp; N(0,1) \newline<br>     \log \sigma_\rho \sim &amp;  N(0,1) \newline<br>     \log \alpha \sim &amp; N(0,1)\newline<br>\end{eqnarray}<br>where </p>
<ul>
<li>Each index $i$ represents a  state in the US.</li>
<li>Each index $j$ represents a particular date.</li>
<li>$y_{i,j}$ is the number of hospital admissions on  state $i$ at date $j$.</li>
<li>the  <em>random effects (random intercept)</em>  $\rho_i$ for different states $i$ are independent and have a normal distribution. It will be fit to the data.</li>
<li>$x_{i,j}$ is the percentage of the state population fully vaccinated on state $i$ at date $j$.</li>
<li>$t_j$ is the number of days elapsed since the beginning of the training period.</li>
<li>$P_i$ is the population of  state $i$.</li>
<li>$\bar{y}$ is log of the average per person incidence on the event in the US Population.</li>
<li>the parameters and $\beta_1,\beta_2,\beta_3$ will be fitted to the observed data to maximize agreement with the model.</li>
<li>the parameter $\sigma_\beta$ is our prior uncertainty about the value of $\beta_i$, it is set to 1.</li>
</ul>
<p>To estimate the model coefficients, we will go for <strong>full Bayesian</strong>. </p>
<h3 id="Bayesian-Approach"><a href="#Bayesian-Approach" class="headerlink" title="Bayesian Approach"></a>Bayesian Approach</h3><p>Unlike the classical frequentist methods, in Bayesian analysis, a parameter is summarized by an entire distribution of values instead of one fixed value, and it provides a natural and principled way of combining prior information or expert knowledge with the data observed.</p>
<p>Both Bayesian methods and classical methods have advantages and disadvantages, and there are some similarities. When the sample size is large, Bayesian inference often provides results for parametric models that are very similar to the results produced by frequentist methods. Some advantages to using Bayesian analysis include the following:</p>
<ol>
<li><p>It provides a natural and principled way of combining prior information with data, within a solid decision theoretical framework. You can incorporate past information about a parameter and form a prior distribution for future analysis. </p>
</li>
<li><p>It provides interpretable answers based on <strong>parameter distributions</strong>, such as &#x201C;the true parameter has a probability of 0.95 of falling in a 95% credible interval.&#x201D;</p>
</li>
<li><p>It provides a convenient setting for a wide range of <strong>complex models</strong>, such as the GLMM model we are trying to build but not easy to get an analytical solution. MCMC, along with other numerical methods, makes computations tractable for virtually all parametric models.</p>
</li>
</ol>
<p>The disadvantages of Bayesian are quite obvious as well:</p>
<ol>
<li><p>It does not tell you how to select a prior. There is no correct way to choose a prior. Bayesian inferences require skills to translate subjective prior beliefs into a mathematically formulated prior.</p>
</li>
<li><p>It often comes with a <strong>high computational cost</strong>, especially in models with a large number of parameters. </p>
</li>
</ol>
<p>To solve our model with Bayesian approach, we have to specify the distributions of the parameters/variables. The good thing is that there are convenient functions provided by <code>pymc3</code>. </p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Y_bar=np.log(Y_train.sum()/P_train.sum())</span><br><span class="line">beta0=np.array([Y_bar,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,<span class="hljs-number">0</span>,])</span><br><span class="line">sigma_beta=np.array([<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>,<span class="hljs-number">1</span>])</span><br></pre></td></tr></tbody></table></figure>

<p>I choose $N(0,1)$ for $\beta$s , and $lognormal(0,1)$ for $\sigma_\rho$s just to speed up the convergence.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> pm.Model() <span class="hljs-keyword">as</span> mod:</span><br><span class="line">    beta=pm.Normal(<span class="hljs-string">&quot;beta&quot;</span>,mu=beta0,</span><br><span class="line">                   sigma=sigma_beta,</span><br><span class="line">                   shape=(len(beta0))</span><br><span class="line">                  )</span><br><span class="line">    lsigma_group=pm.Normal(<span class="hljs-string">&quot;lsigma_group&quot;</span>,mu=<span class="hljs-number">0</span>,sigma=<span class="hljs-number">1</span>)</span><br><span class="line">    sigma_group=pm.Deterministic(<span class="hljs-string">&quot;sigma_group&quot;</span>,np.exp(lsigma_group))</span><br><span class="line">    rho=pm.Normal(<span class="hljs-string">&quot;rho&quot;</span>,mu=<span class="hljs-number">0.0</span>,sigma=sigma_group,shape=(K)) <span class="hljs-comment"># a vector of K values</span></span><br><span class="line">    eta=pm.math.dot(X_train.values,beta)+rho[G_train]</span><br><span class="line">    y_hat=pm.Deterministic(<span class="hljs-string">&quot;eta&quot;</span>,pm.math.exp(eta))</span><br><span class="line">    a=pm.Lognormal(<span class="hljs-string">&quot;alpha&quot;</span>,mu=<span class="hljs-number">0</span>,sigma=<span class="hljs-number">1</span>)</span><br><span class="line">    y=pm.NegativeBinomial(<span class="hljs-string">&quot;y&quot;</span>,mu=y_hat*P_train,alpha=a,observed=Y_train)</span><br></pre></td></tr></tbody></table></figure>

<p>Then we can start the Monte Carlo sampling process. 4 chains, of which 1000 samples are generated. That means there will be 4000 samples for each of the parameters. Be patient, the computation can take a while. (Honestly, sometimes HOURS if using personal laptops)</p>
<h3 id="Monte-Carlo-Sampling"><a href="#Monte-Carlo-Sampling" class="headerlink" title="Monte Carlo Sampling"></a>Monte Carlo Sampling</h3><figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> mod:</span><br><span class="line">    trace = pm.sample(<span class="hljs-number">1000</span>,chains=<span class="hljs-number">4</span>,cores=<span class="hljs-number">4</span>, tune=<span class="hljs-number">500</span>)</span><br></pre></td></tr></tbody></table></figure>

<pre><code>Auto-assigning NUTS sampler...
Initializing NUTS using jitter+adapt_diag...
Multiprocess sampling (4 chains in 4 jobs)
NUTS: [alpha, rho, lsigma_group, beta]
Sampling 4 chains, 0 divergences: 100%|&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;| 6000/6000 [04:36&lt;00:00, 21.72draws/s]
The acceptance probability does not match the target. It is 0.8915155058428972, but should be close to 0.8. Try to increase the number of tuning steps.
The rhat statistic is larger than 1.05 for some parameters. This indicates slight problems during sampling.
The estimated number of effective samples is smaller than 200 for some parameters.</code></pre>
<h4 id="Regression-Coefficients"><a href="#Regression-Coefficients" class="headerlink" title="Regression Coefficients"></a>Regression Coefficients</h4><p>One of the advantages of Bayesian is that a parameter is summarized by <strong>a distribution of values</strong> instead of a fixed value, which definately helps us get a better understanding of the things going on, like how high the uncertainty is, how much confidence the model has in the estimations.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> mod:</span><br><span class="line">    summary=az.summary(trace, var_names=[<span class="hljs-string">&quot;beta&quot;</span>,<span class="hljs-string">&quot;sigma_group&quot;</span>], fmt=<span class="hljs-string">&quot;wide&quot;</span>,round_to=<span class="hljs-number">2</span>)</span><br><span class="line">summary.index=[<span class="hljs-string">&quot;intercept&quot;</span>,<span class="hljs-string">&quot;vaccinated&quot;</span>,<span class="hljs-string">&quot;T&quot;</span>,<span class="hljs-string">&quot;T2&quot;</span>,<span class="hljs-string">&quot;sigma_group&quot;</span>]</span><br><span class="line">summary</span><br></pre></td></tr></tbody></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_mean</th>
      <th>ess_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>intercept</th>
      <td>-9.42</td>
      <td>0.31</td>
      <td>-10.06</td>
      <td>-8.84</td>
      <td>0.02</td>
      <td>0.02</td>
      <td>160.54</td>
      <td>160.54</td>
      <td>142.03</td>
      <td>351.53</td>
      <td>1.04</td>
    </tr>
    <tr>
      <th>vaccinated</th>
      <td>-5.36</td>
      <td>0.66</td>
      <td>-6.57</td>
      <td>-4.02</td>
      <td>0.05</td>
      <td>0.04</td>
      <td>149.80</td>
      <td>119.62</td>
      <td>150.75</td>
      <td>192.52</td>
      <td>1.04</td>
    </tr>
    <tr>
      <th>T</th>
      <td>1.79</td>
      <td>0.07</td>
      <td>1.66</td>
      <td>1.91</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>749.07</td>
      <td>749.07</td>
      <td>751.34</td>
      <td>1212.85</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>T2</th>
      <td>-0.37</td>
      <td>0.06</td>
      <td>-0.47</td>
      <td>-0.25</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>916.41</td>
      <td>916.41</td>
      <td>917.97</td>
      <td>1287.44</td>
      <td>1.01</td>
    </tr>
    <tr>
      <th>sigma_group</th>
      <td>0.55</td>
      <td>0.06</td>
      <td>0.43</td>
      <td>0.66</td>
      <td>0.00</td>
      <td>0.00</td>
      <td>1010.83</td>
      <td>1010.83</td>
      <td>1001.36</td>
      <td>1747.82</td>
      <td>1.00</td>
    </tr>
  </tbody>
</table>
</div>



<p>We can see the distribution of parameters very clearly,</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> mod:</span><br><span class="line">    az.plot_trace(trace,var_names=[<span class="hljs-string">&quot;beta&quot;</span>,<span class="hljs-string">&quot;sigma_group&quot;</span>,<span class="hljs-string">&quot;alpha&quot;</span>])</span><br></pre></td></tr></tbody></table></figure>

<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_27_0.png">


<h4 id="Random-Effects"><a href="#Random-Effects" class="headerlink" title="Random Effects"></a>Random Effects</h4><p>We also get a distribution for the  random, state specific, effects.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> mod:</span><br><span class="line">    random_effects=az.summary(trace, var_names=[<span class="hljs-string">&quot;rho&quot;</span>], fmt=<span class="hljs-string">&quot;wide&quot;</span>,round_to=<span class="hljs-number">2</span>)</span><br><span class="line">random_effects.index=states</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_effects.head(<span class="hljs-number">9</span>)</span><br></pre></td></tr></tbody></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_mean</th>
      <th>ess_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>AK</th>
      <td>0.03</td>
      <td>0.09</td>
      <td>-0.15</td>
      <td>0.20</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>63.60</td>
      <td>63.60</td>
      <td>65.35</td>
      <td>339.69</td>
      <td>1.05</td>
    </tr>
    <tr>
      <th>AL</th>
      <td>0.55</td>
      <td>0.12</td>
      <td>0.33</td>
      <td>0.77</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>88.48</td>
      <td>88.48</td>
      <td>86.71</td>
      <td>428.54</td>
      <td>1.04</td>
    </tr>
    <tr>
      <th>AR</th>
      <td>0.71</td>
      <td>0.11</td>
      <td>0.51</td>
      <td>0.92</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>74.26</td>
      <td>74.26</td>
      <td>74.61</td>
      <td>435.70</td>
      <td>1.05</td>
    </tr>
    <tr>
      <th>AZ</th>
      <td>0.12</td>
      <td>0.08</td>
      <td>-0.04</td>
      <td>0.27</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>49.42</td>
      <td>49.42</td>
      <td>51.50</td>
      <td>317.49</td>
      <td>1.06</td>
    </tr>
    <tr>
      <th>CA</th>
      <td>0.34</td>
      <td>0.09</td>
      <td>0.19</td>
      <td>0.51</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>47.83</td>
      <td>43.42</td>
      <td>46.91</td>
      <td>344.41</td>
      <td>1.07</td>
    </tr>
    <tr>
      <th>CO</th>
      <td>0.16</td>
      <td>0.09</td>
      <td>-0.01</td>
      <td>0.34</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>45.42</td>
      <td>42.62</td>
      <td>44.54</td>
      <td>297.58</td>
      <td>1.07</td>
    </tr>
    <tr>
      <th>CT</th>
      <td>0.10</td>
      <td>0.13</td>
      <td>-0.18</td>
      <td>0.33</td>
      <td>0.02</td>
      <td>0.01</td>
      <td>76.68</td>
      <td>76.68</td>
      <td>72.85</td>
      <td>279.41</td>
      <td>1.05</td>
    </tr>
    <tr>
      <th>DC</th>
      <td>-0.31</td>
      <td>0.12</td>
      <td>-0.52</td>
      <td>-0.09</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>75.16</td>
      <td>75.16</td>
      <td>74.36</td>
      <td>724.17</td>
      <td>1.04</td>
    </tr>
    <tr>
      <th>DE</th>
      <td>-0.48</td>
      <td>0.10</td>
      <td>-0.67</td>
      <td>-0.28</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>74.12</td>
      <td>74.12</td>
      <td>72.69</td>
      <td>614.42</td>
      <td>1.05</td>
    </tr>
  </tbody>
</table>
</div>



<p>Comparing to the other states, states such as FL, KY which are seen as outliers in our previous models have much larger random effects.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">random_effects.loc[[<span class="hljs-string">&apos;FL&apos;</span>,<span class="hljs-string">&apos;KY&apos;</span>]]</span><br></pre></td></tr></tbody></table></figure>




<div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

<pre><code>.dataframe tbody tr th &#123;
    vertical-align: top;
&#125;

.dataframe thead th &#123;
    text-align: right;
&#125;</code></pre>
<p></style><p></p>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>mean</th>
      <th>sd</th>
      <th>hdi_3%</th>
      <th>hdi_97%</th>
      <th>mcse_mean</th>
      <th>mcse_sd</th>
      <th>ess_mean</th>
      <th>ess_sd</th>
      <th>ess_bulk</th>
      <th>ess_tail</th>
      <th>r_hat</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>FL</th>
      <td>1.64</td>
      <td>0.08</td>
      <td>1.48</td>
      <td>1.78</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>44.39</td>
      <td>43.59</td>
      <td>45.16</td>
      <td>292.35</td>
      <td>1.07</td>
    </tr>
    <tr>
      <th>KY</th>
      <td>0.99</td>
      <td>0.08</td>
      <td>0.85</td>
      <td>1.16</td>
      <td>0.01</td>
      <td>0.01</td>
      <td>45.57</td>
      <td>44.32</td>
      <td>47.46</td>
      <td>324.94</td>
      <td>1.06</td>
    </tr>
  </tbody>
</table>
</div>



<h2 id="In-Sample-Predictions"><a href="#In-Sample-Predictions" class="headerlink" title="In Sample Predictions"></a>In Sample Predictions</h2><p>Now, let&#x2019;s make some predictions and see how the mixed model works.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">select_data</span>(<span class="hljs-params">data,periods</span>):</span></span><br><span class="line">    dates=data[<span class="hljs-string">&quot;date&quot;</span>].unique()</span><br><span class="line">    selected_dates=covid.select_dates(dates,periods)</span><br><span class="line">    used_data=data.merge(selected_dates,on=<span class="hljs-string">&quot;date&quot;</span>)</span><br><span class="line">    <span class="hljs-keyword">return</span> used_data.groupby(<span class="hljs-string">&quot;date&quot;</span>)</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_result</span>(<span class="hljs-params">data,norm,ax</span>):</span></span><br><span class="line">    P=data[<span class="hljs-string">&quot;population&quot;</span>]</span><br><span class="line">    m=ax.scatter(data[<span class="hljs-string">&quot;vaccinated&quot;</span>],data[event]/data[<span class="hljs-string">&quot;population&quot;</span>]*<span class="hljs-number">100</span>_000,</span><br><span class="line">                c=P,norm=norm,cmap=<span class="hljs-string">&quot;Greys&quot;</span>,label=event)</span><br><span class="line">    </span><br><span class="line">    ax.errorbar(data[<span class="hljs-string">&quot;vaccinated&quot;</span>],data[<span class="hljs-string">&quot;y_pred&quot;</span>],yerr=data[<span class="hljs-string">&quot;y_std&quot;</span>],fmt=<span class="hljs-string">&quot;D&quot;</span>,alpha=<span class="hljs-number">0.25</span>,</span><br><span class="line">               label=<span class="hljs-string">&quot;predicted&quot;</span>)<span class="hljs-comment">#,c=P,norm=norm,cmap=&quot;Blues&quot;,label=&quot;predicted&quot;)</span></span><br><span class="line">    ax.set_xlabel(<span class="hljs-string">&quot;vaccinated&quot;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="hljs-string">f&quot;<span class="hljs-subst">{event}</span> per 100k&quot;</span>)</span><br><span class="line">    ax.legend()</span><br><span class="line">    <span class="hljs-keyword">return</span> m</span><br><span class="line"></span><br><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_time_facets</span>(<span class="hljs-params">data,event</span>):</span></span><br><span class="line">    <span class="hljs-comment"># Create two subplots and unpack the output array immediately</span></span><br><span class="line">    fig, axes = plt.subplots(<span class="hljs-number">2</span>, <span class="hljs-number">2</span>, figsize=(<span class="hljs-number">14</span>,<span class="hljs-number">12</span>),sharey=<span class="hljs-literal">True</span>,sharex=<span class="hljs-literal">True</span>)</span><br><span class="line">    P=data[<span class="hljs-string">&quot;population&quot;</span>]</span><br><span class="line">    norm=matplotlib.colors.LogNorm(vmin=<span class="hljs-number">100</span>_000, vmax=P.max(), clip=<span class="hljs-literal">False</span>)</span><br><span class="line">    count=<span class="hljs-number">0</span></span><br><span class="line">    <span class="hljs-keyword">for</span> date,group <span class="hljs-keyword">in</span> select_data(data,<span class="hljs-number">4</span>):</span><br><span class="line">        col=count %<span class="hljs-number">2</span> </span><br><span class="line">        row=count //<span class="hljs-number">2</span></span><br><span class="line">        ax=axes[row][col]</span><br><span class="line">        ax.set_title(date.strftime(<span class="hljs-string">&quot;%Y-%m-%d&quot;</span>))</span><br><span class="line">        im=plot_result(group,norm,ax)</span><br><span class="line">        count+=<span class="hljs-number">1</span></span><br><span class="line">    cbar = fig.colorbar(im, ax=axes.ravel().tolist(), shrink=<span class="hljs-number">0.5</span>,label=<span class="hljs-string">&quot;population&quot;</span>)</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> pm.Model() <span class="hljs-keyword">as</span> mod:</span><br><span class="line">    y_pred=pm.NegativeBinomial(<span class="hljs-string">&quot;y_pred&quot;</span>,mu=y_hat*<span class="hljs-number">100</span>_000,alpha=a,shape=(len(X_train)))</span><br><span class="line">    posterior_predictive = pm.sample_posterior_predictive(trace, var_names=[<span class="hljs-string">&quot;y_pred&quot;</span>])</span><br></pre></td></tr></tbody></table></figure>

<pre><code>100%|&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;| 4000/4000 [00:05&lt;00:00, 798.51it/s]</code></pre>
<p>Remember, there are 4000 sample predictions for each of the records, I won&#x2019;t plot out all of them, but will do their means with one standard deviation of uncertainty. The error bars would make prefect graphical representations.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">predicted=posterior_predictive[<span class="hljs-string">&quot;y_pred&quot;</span>]</span><br><span class="line">predicted.shape,train_data.shape</span><br></pre></td></tr></tbody></table></figure>




<pre><code>((4000, 1632), (1632, 6))</code></pre>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">y_pred_mean=predicted.mean(axis=<span class="hljs-number">0</span>)</span><br><span class="line">y_pred_std=predicted.std(axis=<span class="hljs-number">0</span>)</span><br><span class="line"></span><br><span class="line">data=train_data.copy()</span><br><span class="line">data[<span class="hljs-string">&quot;y_pred&quot;</span>]=y_pred_mean</span><br><span class="line">data[<span class="hljs-string">&quot;y_std&quot;</span>]=y_pred_std</span><br></pre></td></tr></tbody></table></figure>

<p>Looks like the predictions are closer to the actuals since we incorporate the random effects. Hooray!</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_time_facets(data,event)</span><br></pre></td></tr></tbody></table></figure>

<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_43_0.png">


<h2 id="Differences-comparing-to-linear-regression"><a href="#Differences-comparing-to-linear-regression" class="headerlink" title="Differences comparing to linear regression"></a>Differences comparing to linear regression</h2><h3 id="Random-Intercepts"><a href="#Random-Intercepts" class="headerlink" title="Random Intercepts"></a>Random Intercepts</h3><p>Let&#x2019;s take a further look by state to better understand what I meant by random effects/intercepts.</p>
<p>Below is all the observed data points marked by state. We can see that roughly the slopes of different groups are close, while the intercepts can vary.</p>
<p>In case you wonder why the slopes are upward, that&#x2019;s due to the passage of time, remember time is our explanatory variable as well, but we can only plot two dimensions.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">fig, ax = plt.subplots()</span><br><span class="line">P=data[<span class="hljs-string">&quot;population&quot;</span>]</span><br><span class="line">norm=matplotlib.colors.LogNorm(vmin=<span class="hljs-number">100</span>_000, vmax=P.max(), clip=<span class="hljs-literal">False</span>)</span><br><span class="line">m=ax.scatter(data[<span class="hljs-string">&quot;vaccinated&quot;</span>],data[event]/data[<span class="hljs-string">&quot;population&quot;</span>]*<span class="hljs-number">100</span>_000,</span><br><span class="line">            c=P,norm=norm,cmap=<span class="hljs-string">&quot;Greys&quot;</span>,label=event, s = <span class="hljs-number">5</span>)</span><br><span class="line">ax.set_xlabel(<span class="hljs-string">&quot;vaccinated&quot;</span>)</span><br><span class="line">ax.set_ylabel(<span class="hljs-string">f&quot;<span class="hljs-subst">{event}</span> per 100k by state&quot;</span>)</span><br><span class="line">ax.legend()</span><br></pre></td></tr></tbody></table></figure>



<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_46_1.png">



<p>Let&#x2019;s select three states in the middle to plot their predictions against actuals.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_states</span>(<span class="hljs-params">data, states, var</span>):</span></span><br><span class="line">    data = data[data[<span class="hljs-string">&apos;state&apos;</span>].isin(states)]</span><br><span class="line">    data = data.sort_values(<span class="hljs-string">&apos;vaccinated&apos;</span>)</span><br><span class="line">    x = data[var]</span><br><span class="line">    y = data[<span class="hljs-string">&quot;y_pred&quot;</span>]</span><br><span class="line">    std = data[<span class="hljs-string">&quot;y_std&quot;</span>]</span><br><span class="line">    cmp=cm.get_cmap(<span class="hljs-string">&quot;tab10&quot;</span>)</span><br><span class="line">    plt.xlim([<span class="hljs-number">0.4475</span>,<span class="hljs-number">0.466</span>])</span><br><span class="line">    plt.scatter(x,y, c=<span class="hljs-string">&apos;black&apos;</span>,s=<span class="hljs-number">15</span>)</span><br><span class="line">    colors = np.array([<span class="hljs-string">&apos;tab:blue&apos;</span>,<span class="hljs-string">&apos;tab:green&apos;</span>,<span class="hljs-string">&apos;tab:orange&apos;</span>,<span class="hljs-string">&apos;tab:red&apos;</span>])</span><br><span class="line">    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(len(states)):</span><br><span class="line">        s = states[i]</span><br><span class="line">        ds = data[data[<span class="hljs-string">&apos;state&apos;</span>]==s]</span><br><span class="line">        x = ds[var]</span><br><span class="line">        y = ds[<span class="hljs-string">&quot;y_pred&quot;</span>]</span><br><span class="line">        std = ds[<span class="hljs-string">&quot;y_std&quot;</span>]</span><br><span class="line">        color = colors[i]</span><br><span class="line">        plt.plot(x,y,<span class="hljs-string">&apos;k-&apos;</span>,color=color,linewidth=<span class="hljs-number">2.0</span>, label=<span class="hljs-string">f&quot;predicted <span class="hljs-subst">{s}</span>&quot;</span>)</span><br><span class="line">        plt.fill_between(x,y+std,y-std,alpha=<span class="hljs-number">0.15</span>,color=color)</span><br><span class="line">        plt.xlabel(<span class="hljs-string">&quot;vaccinated&quot;</span>)</span><br><span class="line">        plt.ylabel(<span class="hljs-string">f&quot;<span class="hljs-subst">{event}</span> per 100k by state&quot;</span>)</span><br><span class="line">        plt.legend(loc=<span class="hljs-string">&quot;upper left&quot;</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>This shows clearly how the mixed model leverages all the data points to estimate the correlation (slope) between admissions and vaccinations, but at the same time allows states to have different starts (intercept) due to fundamental differences which we consider are random.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_states(data,[<span class="hljs-string">&apos;KY&apos;</span>,<span class="hljs-string">&apos;AK&apos;</span>,<span class="hljs-string">&apos;KS&apos;</span>],<span class="hljs-string">&quot;vaccinated&quot;</span>)</span><br></pre></td></tr></tbody></table></figure>

<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_50_0.png">


<h3 id="Variance"><a href="#Variance" class="headerlink" title="Variance"></a>Variance</h3><p>The Bayesian approach gives the distributions of the predictions, so we don&#x2019;t need to rack our brains for the analytical solution of the prediction band, instead, we can simply plot it out with the samples generated by <code>pymc3</code>. Here I used one unit of the sample standard deviation. </p>
<p>As we can see, the variance of prediction is larger with greater admissions, meaning they are positively correlated, which is not what we&#x2019;ve seen with the linear regression that the variance of dependent variable is always constant. So using GLMM <strong>based on a negative binomial distribution</strong> allows the magnitude of the variance to change as a function of the predicted value.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">plot_state</span>(<span class="hljs-params">data, state, color</span>):</span></span><br><span class="line">    data = data[data[<span class="hljs-string">&apos;state&apos;</span>]==state]</span><br><span class="line">    fig, ax = plt.subplots()</span><br><span class="line">    ax.scatter(data[<span class="hljs-string">&quot;vaccinated&quot;</span>],data[event]/data[<span class="hljs-string">&quot;population&quot;</span>]*<span class="hljs-number">100</span>_000,c=<span class="hljs-string">&apos;black&apos;</span>,s=<span class="hljs-number">15</span>,label=event)    </span><br><span class="line">    ax.errorbar(data[<span class="hljs-string">&quot;vaccinated&quot;</span>],data[<span class="hljs-string">&quot;y_pred&quot;</span>],yerr=data[<span class="hljs-string">&quot;y_std&quot;</span>],fmt=<span class="hljs-string">&quot;o&quot;</span>,alpha=<span class="hljs-number">0.25</span>,c=color,</span><br><span class="line">               label=<span class="hljs-string">&quot;predicted&quot;</span>)</span><br><span class="line">    ax.set_xlabel(<span class="hljs-string">&quot;vaccinated&quot;</span>)</span><br><span class="line">    ax.set_ylabel(<span class="hljs-string">f&quot;<span class="hljs-subst">{event}</span> per 100k&quot;</span>)</span><br><span class="line">    ax.legend()</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_state(data,<span class="hljs-string">&apos;KY&apos;</span>,<span class="hljs-string">&apos;tab:blue&apos;</span>)</span><br></pre></td></tr></tbody></table></figure>

<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_53_0.png">



<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">plot_state(data,<span class="hljs-string">&apos;FL&apos;</span>,<span class="hljs-string">&apos;tab:green&apos;</span>)</span><br></pre></td></tr></tbody></table></figure>

<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_54_0.png">


<h2 id="Predicted-Dependence-on-vaccination-Rate"><a href="#Predicted-Dependence-on-vaccination-Rate" class="headerlink" title="Predicted Dependence on vaccination Rate"></a>Predicted Dependence on vaccination Rate</h2><p>One of the things that we are interested is that how does the vaccination rate impact the admissions?</p>
<p>To see this better, I fixed the time at Aug.15, and let the vaccination rate to vary from 20% to 100%.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># given current time point, generate test set for vaccination rate from 20% to 100%</span></span><br><span class="line">V_N=<span class="hljs-number">201</span></span><br><span class="line">V=np.linspace(<span class="hljs-number">0.2</span>,<span class="hljs-number">1</span>,V_N)</span><br><span class="line">T=np.ones(V_N)</span><br><span class="line">T2=T**<span class="hljs-number">2</span></span><br><span class="line">X2_test=np.c_[np.ones(T_N),V,T,T2]</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> pm.Model() <span class="hljs-keyword">as</span> mod:</span><br><span class="line">    eta2_pred=pm.math.dot(X2_test,beta)</span><br><span class="line">    y_pred2=pm.Deterministic(<span class="hljs-string">&quot;y_pred2&quot;</span>,pm.math.exp(eta2_pred)*<span class="hljs-number">100</span>_000)</span><br><span class="line">    posterior_predictive = pm.sample_posterior_predictive(trace, var_names=[<span class="hljs-string">&quot;y_pred2&quot;</span>])</span><br></pre></td></tr></tbody></table></figure>

<pre><code>100%|&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;| 4000/4000 [00:01&lt;00:00, 3891.10it/s]</code></pre>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># generate predicted mean and standard deviation</span></span><br><span class="line">predicted=posterior_predictive[<span class="hljs-string">&quot;y_pred2&quot;</span>]</span><br><span class="line">y_pred_mean=predicted.mean(axis=<span class="hljs-number">0</span>)</span><br><span class="line">y_pred_std=predicted.std(axis=<span class="hljs-number">0</span>)</span><br></pre></td></tr></tbody></table></figure>

<p>We can see that vaccinations and admissions are negatively correlated. And when vaccination rate is low, the prediction can be quite uncertain.</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">plt.plot(V,y_pred_mean,<span class="hljs-string">&quot;k--&quot;</span>,linewidth=<span class="hljs-number">1</span>)</span><br><span class="line">plt.fill_between(V,y_pred_mean+y_pred_std,y_pred_mean-y_pred_std,alpha=<span class="hljs-number">0.07</span>,color=<span class="hljs-string">&quot;k&quot;</span>)</span><br><span class="line">plt.fill_between(V,y_pred_mean+<span class="hljs-number">2</span>*y_pred_std,y_pred_mean<span class="hljs-number">-2</span>*y_pred_std,alpha=<span class="hljs-number">0.07</span>,color=<span class="hljs-string">&quot;k&quot;</span>)</span><br><span class="line">plt.xlabel(<span class="hljs-string">&quot;Vaccinated&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">f&quot;<span class="hljs-subst">{event}</span> per 100k&quot;</span>)</span><br></pre></td></tr></tbody></table></figure>



<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_61_1.png">



<h2 id="Predicted-Time-Evolution"><a href="#Predicted-Time-Evolution" class="headerlink" title="Predicted Time Evolution"></a>Predicted Time Evolution</h2><p>The other thing that we are most interested in is that how the third wave of covid19 is going to evolve. How many admissions are there going to be given the current vaccination rate? So I use the GLMM model to project the next two months from Aug.15th on. </p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># given the average vaccination rates</span></span><br><span class="line">mean_vac=(train_data[<span class="hljs-string">&quot;vaccinated&quot;</span>]*train_data[<span class="hljs-string">&quot;population&quot;</span>]).sum()/train_data[<span class="hljs-string">&quot;population&quot;</span>].sum()</span><br><span class="line">mean_vac</span><br></pre></td></tr></tbody></table></figure>




<pre><code>0.48852180987716365</code></pre>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># generate test set for the past month and the next 2 months</span></span><br><span class="line">T_N=<span class="hljs-number">201</span></span><br><span class="line">T=np.linspace(<span class="hljs-number">0</span>,<span class="hljs-number">3</span>,T_N)</span><br><span class="line">T2=T**<span class="hljs-number">2</span></span><br><span class="line">X1_test=np.c_[np.ones(T_N),mean_vac*np.ones(T_N),T,T2]</span><br></pre></td></tr></tbody></table></figure>


<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-keyword">with</span> pm.Model() <span class="hljs-keyword">as</span> mod:</span><br><span class="line">    eta1_pred=pm.math.dot(X1_test,beta)</span><br><span class="line">    y_pred1=pm.Deterministic(<span class="hljs-string">&quot;y_pred1&quot;</span>,pm.math.exp(eta1_pred)*<span class="hljs-number">100</span>_000)</span><br><span class="line">    posterior_predictive = pm.sample_posterior_predictive(trace, var_names=[<span class="hljs-string">&quot;y_pred1&quot;</span>])</span><br></pre></td></tr></tbody></table></figure>

<pre><code>100%|&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;&#x2588;| 4000/4000 [00:01&lt;00:00, 3831.47it/s]</code></pre>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="hljs-comment"># generate predicted mean and standard deviation</span></span><br><span class="line">predicted=posterior_predictive[<span class="hljs-string">&quot;y_pred1&quot;</span>]</span><br><span class="line">y_pred_mean=predicted.mean(axis=<span class="hljs-number">0</span>)</span><br><span class="line">y_pred_std=predicted.std(axis=<span class="hljs-number">0</span>)</span><br></pre></td></tr></tbody></table></figure>

<p><strong>The prediction tells us that the admission will peak in one and half month from Aug.15th, which is by the end of September.</strong> However, I would be careful as the model have low confidence when projecting beyond one month. Look at that wide confidential interval band after T=2. Basically, the reality can fall any where between the curve flattening out as early as the start of September to that we won&#x2019;t be able to see a peak until mid October. But overall I am very optimistic as there&#x2019;s at least 80% of chance that we&#x2019;ll see it peaking before mid October. Eventually, we will get there. So hang in there, everyone!!</p>
<figure class="highlight python hljs"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">T0=T[T&lt;<span class="hljs-number">1</span>]</span><br><span class="line">plt.plot(T0,y_pred_mean[T&lt;<span class="hljs-number">1</span>],<span class="hljs-string">&quot;k&quot;</span>,linewidth=<span class="hljs-number">4</span>,label=<span class="hljs-string">&quot;fitted&quot;</span>)</span><br><span class="line">plt.plot(T,y_pred_mean,<span class="hljs-string">&quot;k--&quot;</span>,linewidth=<span class="hljs-number">1</span>,label=<span class="hljs-string">&quot;extrapolated&quot;</span>)</span><br><span class="line">plt.fill_between(T,y_pred_mean+y_pred_std,y_pred_mean-y_pred_std,alpha=<span class="hljs-number">0.07</span>,color=<span class="hljs-string">&quot;k&quot;</span>)</span><br><span class="line">plt.fill_between(T,y_pred_mean+<span class="hljs-number">2</span>*y_pred_std,y_pred_mean<span class="hljs-number">-2</span>*y_pred_std,alpha=<span class="hljs-number">0.07</span>,color=<span class="hljs-string">&quot;k&quot;</span>,)</span><br><span class="line">plt.xlabel(<span class="hljs-string">&quot;T (months)&quot;</span>)</span><br><span class="line">plt.ylabel(<span class="hljs-string">f&quot;<span class="hljs-subst">{event}</span> per 100k&quot;</span>)</span><br><span class="line">plt.legend(loc=<span class="hljs-string">&quot;lower right&quot;</span>)</span><br></pre></td></tr></tbody></table></figure>




<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_68_1.png">



<p>Officially we are done, cheers! I hope you find this project inspiring. And if you read it all the way through - congrats, you are an incredibly patient person, have a cookie!</p>
<img src="http://yumeng-li.github.io/projectcovidmixed_files/projectcovidmixed_cookie.png" width="400">
</body></html>
    
    </div>
    
    
    <div class="columns is-mobile is-multiline article-nav">
        <span class="column is-12-mobile is-half-desktop  article-nav-prev">
            
            <a href="/2021/11/16/VECM/">Predicting Post-Pandemic Consumption Behaviors Given Potential Paths of Monetary Policy, Part 1 -- Economic Theories, Structural Breaks and Stationarity</a>
            
        </span>
        <span class="column is-12-mobile is-half-desktop  article-nav-next">
            
            <a href="/2021/09/26/projectcovidGLM/">Project Covid Admissions Based on Vaccine Progress, Part 2 -- Generalized Linear Models, From Poisson Regression to Negative Binomial Regression</a>
            
        </span>
    </div>
    
</article>




    </div>
</section>
    <footer class="footer">
    <div class="container">
        <div class="columns content">
            <div class="column is-narrow has-text-centered">
                &copy; 2025 Yumeng Li&nbsp;
                Powered by <a href="http://hexo.io/" target="_blank">Hexo</a> & <a
                        target="_blank" rel="noopener" href="http://github.com/ppoffice/hexo-theme-minos">Minos</a>
            </div>
            <div class="column is-hidden-mobile"></div>

            
            <div class="column is-narrow">
                <div class="columns is-mobile is-multiline is-centered">
                
                    
                <a class="column is-narrow has-text-black" title="GitHub" target="_blank" rel="noopener" href="https://github.com/ppoffice/hexo-theme-minos">
                    
                    GitHub
                    
                </a>
                
                </div>
            </div>
            
            
        </div>
    </div>
</footer>
    <script src="//cdnjs.cloudflare.com/ajax/libs/jquery/3.3.1/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/moment.js/2.22.2/moment-with-locales.min.js"></script>

<!-- test if the browser is outdated -->
<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" target="_blank" rel="noopener" href="http://outdatedbrowser.com/">Update my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="//cdnjs.cloudflare.com/ajax/libs/outdated-browser/1.1.5/outdatedbrowser.min.js"></script>
<script>
    $(document).ready(function () {
        // plugin function, place inside DOM ready function
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        })
    });
</script>

<script>
    window.FontAwesomeConfig = {
        searchPseudoElements: true
    }
    moment.locale("en-AU");
</script>


    
    
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML"></script>
<script>
    MathJax.Hub.Config({
        "HTML-CSS": {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
</script>

    
    
    
    
<script src="//cdnjs.cloudflare.com/ajax/libs/lightgallery/1.6.8/js/lightgallery-all.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/justifiedGallery/3.6.5/js/jquery.justifiedGallery.min.js"></script>
<script>
    (function ($) {
        $(document).ready(function () {
            if (typeof($.fn.lightGallery) === 'function') {
                $('.article.gallery').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof($.fn.justifiedGallery) === 'function') {
                $('.justified-gallery').justifiedGallery();
            }
        });
    })(jQuery);
</script>

    
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.0/clipboard.min.js"></script>
    <style>
        .hljs {
            position: relative;
        }

        .hljs .clipboard-btn {
            float: right;
            color: #9a9a9a;
            background: none;
            border: none;
            cursor: pointer;
        }

        .hljs .clipboard-btn:hover {
          color: #8a8a8a;
        }

        .hljs > .clipboard-btn {
            display: none;
            position: absolute;
            right: 4px;
            top: 4px;
        }

        .hljs:hover > .clipboard-btn {
            display: inline;
        }

        .hljs > figcaption > .clipboard-btn {
            margin-right: 4px;
        }
    </style>
    <script>
      $(document).ready(function () {
        $('figure.hljs').each(function(i, figure) {
          var codeId = 'code-' + i;
          var code = figure.querySelector('.code');
          var copyButton = $('<button>Copy <i class="far fa-clipboard"></i></button>');
          code.id = codeId;
          copyButton.addClass('clipboard-btn');
          copyButton.attr('data-clipboard-target-id', codeId);

          var figcaption = figure.querySelector('figcaption');

          if (figcaption) {
            figcaption.append(copyButton[0]);
          } else {
            figure.prepend(copyButton[0]);
          }
        })

        var clipboard = new ClipboardJS('.clipboard-btn', {
          target: function(trigger) {
            return document.getElementById(trigger.getAttribute('data-clipboard-target-id'));
          }
        });
        clipboard.on('success', function(e) {
          e.clearSelection();
        })
      })
    </script>

    
    

    



<script src="/js/script.js"></script>


    
    <div class="searchbox ins-search">
    <div class="searchbox-mask"></div>
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>

<script src="/js/insight.js"></script>

    
</body>
</html>